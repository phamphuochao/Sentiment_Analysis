{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. KHAI B√ÅO TH∆Ø VI·ªÜN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. LOAD DATA V√Ä XEM D·ªÆ LI·ªÜU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\HaoPham\\AppData\\Local\\Temp\\ipykernel_10468\\3030248052.py:1: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  data = pd.read_csv(\"D:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\data_source\\sentimentdataset.csv\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Enjoying a beautiful day at the park!        ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Traffic was terrible this morning.           ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>Just finished an amazing workout! üí™          ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Excited about the upcoming weekend getaway!  ...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>Trying out a new recipe for dinner tonight.  ...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0  \\\n",
       "0             0           0   \n",
       "1             1           1   \n",
       "2             2           2   \n",
       "3             3           3   \n",
       "4             4           4   \n",
       "\n",
       "                                                Text    Sentiment  \\\n",
       "0   Enjoying a beautiful day at the park!        ...   Positive     \n",
       "1   Traffic was terrible this morning.           ...   Negative     \n",
       "2   Just finished an amazing workout! üí™          ...   Positive     \n",
       "3   Excited about the upcoming weekend getaway!  ...   Positive     \n",
       "4   Trying out a new recipe for dinner tonight.  ...   Neutral      \n",
       "\n",
       "             Timestamp            User     Platform  \\\n",
       "0  2023-01-15 12:30:00   User123          Twitter     \n",
       "1  2023-01-15 08:45:00   CommuterX        Twitter     \n",
       "2  2023-01-15 15:45:00   FitnessFan      Instagram    \n",
       "3  2023-01-15 18:20:00   AdventureX       Facebook    \n",
       "4  2023-01-15 19:55:00   ChefCook        Instagram    \n",
       "\n",
       "                                     Hashtags  Retweets  Likes       Country  \\\n",
       "0   #Nature #Park                                  15.0   30.0     USA         \n",
       "1   #Traffic #Morning                               5.0   10.0     Canada      \n",
       "2   #Fitness #Workout                              20.0   40.0   USA           \n",
       "3   #Travel #Adventure                              8.0   15.0     UK          \n",
       "4   #Cooking #Food                                 12.0   25.0    Australia    \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"D:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\data_source\\sentimentdataset.csv\")\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. KI·ªÇM TRA V√Ä T√åM HI·ªÇU D·ªÆ LI·ªÜU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 15 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Unnamed: 0.1  732 non-null    int64  \n",
      " 1   Unnamed: 0    732 non-null    int64  \n",
      " 2   Text          732 non-null    object \n",
      " 3   Sentiment     732 non-null    object \n",
      " 4   Timestamp     732 non-null    object \n",
      " 5   User          732 non-null    object \n",
      " 6   Platform      732 non-null    object \n",
      " 7   Hashtags      732 non-null    object \n",
      " 8   Retweets      732 non-null    float64\n",
      " 9   Likes         732 non-null    float64\n",
      " 10  Country       732 non-null    object \n",
      " 11  Year          732 non-null    int64  \n",
      " 12  Month         732 non-null    int64  \n",
      " 13  Day           732 non-null    int64  \n",
      " 14  Hour          732 non-null    int64  \n",
      "dtypes: float64(2), int64(6), object(7)\n",
      "memory usage: 85.9+ KB\n"
     ]
    }
   ],
   "source": [
    "# Th√¥ng tin v·ªÅ d·ªØ li·ªáu\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <td>732.0</td>\n",
       "      <td>366.464481</td>\n",
       "      <td>211.513936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>183.75</td>\n",
       "      <td>366.5</td>\n",
       "      <td>549.25</td>\n",
       "      <td>732.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>732.0</td>\n",
       "      <td>369.740437</td>\n",
       "      <td>212.428936</td>\n",
       "      <td>0.0</td>\n",
       "      <td>185.75</td>\n",
       "      <td>370.5</td>\n",
       "      <td>553.25</td>\n",
       "      <td>736.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Retweets</th>\n",
       "      <td>732.0</td>\n",
       "      <td>21.508197</td>\n",
       "      <td>7.061286</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.75</td>\n",
       "      <td>22.0</td>\n",
       "      <td>25.00</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Likes</th>\n",
       "      <td>732.0</td>\n",
       "      <td>42.901639</td>\n",
       "      <td>14.089848</td>\n",
       "      <td>10.0</td>\n",
       "      <td>34.75</td>\n",
       "      <td>43.0</td>\n",
       "      <td>50.00</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>732.0</td>\n",
       "      <td>2020.471311</td>\n",
       "      <td>2.802285</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>2019.00</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>2023.00</td>\n",
       "      <td>2023.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Month</th>\n",
       "      <td>732.0</td>\n",
       "      <td>6.122951</td>\n",
       "      <td>3.411763</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Day</th>\n",
       "      <td>732.0</td>\n",
       "      <td>15.497268</td>\n",
       "      <td>8.474553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.00</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.00</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>732.0</td>\n",
       "      <td>15.521858</td>\n",
       "      <td>4.113414</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>16.0</td>\n",
       "      <td>19.00</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              count         mean         std     min      25%     50%  \\\n",
       "Unnamed: 0.1  732.0   366.464481  211.513936     0.0   183.75   366.5   \n",
       "Unnamed: 0    732.0   369.740437  212.428936     0.0   185.75   370.5   \n",
       "Retweets      732.0    21.508197    7.061286     5.0    17.75    22.0   \n",
       "Likes         732.0    42.901639   14.089848    10.0    34.75    43.0   \n",
       "Year          732.0  2020.471311    2.802285  2010.0  2019.00  2021.0   \n",
       "Month         732.0     6.122951    3.411763     1.0     3.00     6.0   \n",
       "Day           732.0    15.497268    8.474553     1.0     9.00    15.0   \n",
       "Hour          732.0    15.521858    4.113414     0.0    13.00    16.0   \n",
       "\n",
       "                  75%     max  \n",
       "Unnamed: 0.1   549.25   732.0  \n",
       "Unnamed: 0     553.25   736.0  \n",
       "Retweets        25.00    40.0  \n",
       "Likes           50.00    80.0  \n",
       "Year          2023.00  2023.0  \n",
       "Month            9.00    12.0  \n",
       "Day             22.00    31.0  \n",
       "Hour            19.00    23.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Th·ªëng k√™ c∆° b·∫£n\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0.1    0\n",
       "Unnamed: 0      0\n",
       "Text            0\n",
       "Sentiment       0\n",
       "Timestamp       0\n",
       "User            0\n",
       "Platform        0\n",
       "Hashtags        0\n",
       "Retweets        0\n",
       "Likes           0\n",
       "Country         0\n",
       "Year            0\n",
       "Month           0\n",
       "Day             0\n",
       "Hour            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ki·ªÉm tra d·ªØ li·ªáu null\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ki·ªÉm tra d·ªØ li·ªáu tr√πng l·∫∑p\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# T·ªïng quan \n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sau khi ki·ªÉm tra d·ªØ li·ªáu th√¨ c√≥ nh∆∞ng ƒëi·ªÉm ch√≠nh nh∆∞ sau:\n",
    "\n",
    "    + T·ªïng quang: c√≥ 732 d√≤ng v√† 15 c·ªôt\n",
    "    + G√≠a tr·ªã thi·∫øu: kh√¥ng c√≥ gi√° tr·ªã thi·∫øu\n",
    "    + C√°c tr∆∞·ªùng d·ªØ li·ªáu: trong ƒë√≥ ch·ªâ c√≥ 1 tr∆∞·ªùng l√† ph√¢n lo·∫°i: 'Timestamp'(theo d·∫°ng ng√†y),\n",
    "    c√≤n l·∫°i h·∫≠u nh∆∞ l√† theo d·∫°ng s·ªë v√† chu·ªói.\n",
    "    + Ngo·∫°i l·ªá: kh√¥ng c√≥ c√°c ngo·∫°i l·ªá\n",
    "    + C√°c d·ªØ li·ªáu tr√πng l·∫≠p: kh√¥ng c√≥ d·ªØ li·ªáu tr√πng l·∫≠p\n",
    "-----------------------------------------------------------------\n",
    "nh·∫≠n x√©t: d·ªØ li·ªáu hi·ªán ƒëang c√≥ 2 c·ªôt kh√¥ng x√°c ƒë·ªãnh c·∫ßn lo·∫°i b·ªè. C≈©ng nh∆∞ d·ªØ li·ªáu trong m·ªói d√≤ng ·ªü c·ªôt 'Text' c√≥ ch·ªØa c√°c bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c, nh·ªØng c√°i n√†y s·∫Ω g√¢y ra l·ªói khi up n√≥ l√™n SQL. Sau c√πng l√† ƒë·ªãnh d·∫°ng d·ªØ li·ªáu ·ªü c·ªôt 'Timestamp' l·∫°i th√†nh Datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. X·ª≠ l√≠ d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1 X√≥a c√°c d·ªØ li·ªáu l·ªói"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X√≥a c·ªôt 'Unnamed: 0.1', 'Unnamed: 0'\n",
    "df = df.drop(['Unnamed: 0.1', 'Unnamed: 0'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X√≥a c√°c k√≠ t·ª± ƒë·∫∑c bi·ªát\n",
    "# H√†m lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát, emoji v√† gi·ªØ l·∫°i ch·ªØ c√°i, ch·ªØ s·ªë\n",
    "def clean_text(text):\n",
    "    # S·ª≠ d·ª•ng regex ƒë·ªÉ lo·∫°i b·ªè k√Ω t·ª± ƒë·∫∑c bi·ªát v√† emoji\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)  # Ch·ªâ gi·ªØ l·∫°i ch·ªØ c√°i v√† ch·ªØ s·ªë\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # X√≥a kho·∫£ng tr·∫Øng th·ª´a\n",
    "    return text\n",
    "\n",
    "# √Åp d·ª•ng h√†m v√†o c·ªôt 'Text'\n",
    "df['Text'] = df['Text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c√°c tr∆∞·ªùng d·ªØ li·ªáu text\n",
    "# X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c·ªôt 'Platform'\n",
    "df['Platform'] = df['Platform'].str.strip()\n",
    "# X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c·ªôt 'Country'\n",
    "df['Country'] = df['Country'].str.strip()\n",
    "# X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c·ªôt 'Sentiment'\n",
    "df['Sentiment'] = df['Sentiment'].str.strip()\n",
    "# X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c·ªôt 'Hashtags'\n",
    "df['Hashtags'] = df['Hashtags'].str.strip()\n",
    "# X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c·ªôt 'User'\n",
    "df['User'] = df['User'].str.strip()\n",
    "# X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c·ªôt 'Text'\n",
    "df['Text'] = df['Text'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2. Chu·∫©n h√≥a d·ªØ li·ªáu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªïi ƒë·ªãnh d·∫°ng c·ªôt Timestamp th√†nh ki·ªÉu datetime\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "# ƒê·ªïi ƒë·ªãnh d·∫°ng c·ªôt Likes, Retweets th√†nh ki·ªÉu int64\n",
    "df[['Likes', 'Retweets']] = df[['Likes', 'Retweets']].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gi·ªõi h·∫°n chi·ªÅu d√†i chu·ªói t·ªëi ƒëa 255 k√Ω t·ª± c·ªßa c·ªôt Text\n",
    "df['Text'] = df['Text'].str.slice(0, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Data sau khi x·ª≠ l√≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 732 entries, 0 to 731\n",
      "Data columns (total 13 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Text       732 non-null    object        \n",
      " 1   Sentiment  732 non-null    object        \n",
      " 2   Timestamp  732 non-null    datetime64[ns]\n",
      " 3   User       732 non-null    object        \n",
      " 4   Platform   732 non-null    object        \n",
      " 5   Hashtags   732 non-null    object        \n",
      " 6   Retweets   732 non-null    int64         \n",
      " 7   Likes      732 non-null    int64         \n",
      " 8   Country    732 non-null    object        \n",
      " 9   Year       732 non-null    int64         \n",
      " 10  Month      732 non-null    int64         \n",
      " 11  Day        732 non-null    int64         \n",
      " 12  Hour       732 non-null    int64         \n",
      "dtypes: datetime64[ns](1), int64(6), object(6)\n",
      "memory usage: 74.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text Sentiment           Timestamp  \\\n",
       "0        Enjoying a beautiful day at the park  Positive 2023-01-15 12:30:00   \n",
       "1           Traffic was terrible this morning  Negative 2023-01-15 08:45:00   \n",
       "2            Just finished an amazing workout  Positive 2023-01-15 15:45:00   \n",
       "3  Excited about the upcoming weekend getaway  Positive 2023-01-15 18:20:00   \n",
       "4  Trying out a new recipe for dinner tonight   Neutral 2023-01-15 19:55:00   \n",
       "\n",
       "         User   Platform            Hashtags  Retweets  Likes    Country  \\\n",
       "0     User123    Twitter       #Nature #Park        15     30        USA   \n",
       "1   CommuterX    Twitter   #Traffic #Morning         5     10     Canada   \n",
       "2  FitnessFan  Instagram   #Fitness #Workout        20     40        USA   \n",
       "3  AdventureX   Facebook  #Travel #Adventure         8     15         UK   \n",
       "4    ChefCook  Instagram      #Cooking #Food        12     25  Australia   \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 T·∫°o df1 t·ª´ df ƒë√£ c√≥"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.5 Ph√¢n lo·∫°i c√°c c·∫£m x√∫c th√†nh 3 nh√≥m c·∫£m x√∫c ch√≠nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m ph√¢n lo·∫°i c·∫£m x√∫c\n",
    "def classify_sentiment(text):\n",
    "    # Gi·ªØ nguy√™n n·∫øu l√† Neutral\n",
    "    if text.lower() == 'neutral':\n",
    "        return 'Neutral'\n",
    "    else:\n",
    "        # S·ª≠ d·ª•ng TextBlob ƒë·ªÉ x√°c ƒë·ªãnh polarity cho c√°c gi√° tr·ªã kh√°c\n",
    "        analysis = TextBlob(text)\n",
    "        polarity = analysis.sentiment.polarity\n",
    "        \n",
    "        # Ph√¢n lo·∫°i d·ª±a tr√™n polarity\n",
    "        if polarity > 0:\n",
    "            return 'Positive'\n",
    "        else:\n",
    "            return 'Negative'\n",
    "\n",
    "# √Åp d·ª•ng h√†m ph√¢n lo·∫°i cho c·ªôt Sentiment\n",
    "df1['Summarize Sentiment'] = df1['Sentiment'].apply(classify_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X√≥a c·ªôt Sentiment\n",
    "df1 = df1.drop(['Sentiment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ƒê·ªïi v·ªã tr√≠ c·ªôt Summarize Sentiment\n",
    "Summarize_Sentiment = df1.pop('Summarize Sentiment')\n",
    "df1.insert(1, 'Summarize Sentiment', Summarize_Sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√°ch c√°c hashtag b·∫±ng d·∫•u ph·∫©y ho·∫∑c kho·∫£ng tr·∫Øng\n",
    "# df1['Hashtags_Split'] = df1['Hashtags'].str.split('[, ]+')  # S·ª≠ d·ª•ng regex ƒë·ªÉ t√°ch b·∫±ng d·∫•u ph·∫©y ho·∫∑c kho·∫£ng tr·∫Øng\n",
    "# # Chuy·ªÉn t·∫•t c·∫£ hashtag th√†nh m·ªôt danh s√°ch duy nh·∫•t\n",
    "# hashtags = df1['Hashtags_Split'].dropna().sum()  # G·ªôp c√°c danh s√°ch con th√†nh m·ªôt danh s√°ch l·ªõn\n",
    "# hashtags = pd.DataFrame(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Summarize Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text Summarize Sentiment  \\\n",
       "0        Enjoying a beautiful day at the park            Positive   \n",
       "1           Traffic was terrible this morning            Negative   \n",
       "2            Just finished an amazing workout            Positive   \n",
       "3  Excited about the upcoming weekend getaway            Positive   \n",
       "4  Trying out a new recipe for dinner tonight             Neutral   \n",
       "\n",
       "            Timestamp        User   Platform            Hashtags  Retweets  \\\n",
       "0 2023-01-15 12:30:00     User123    Twitter       #Nature #Park        15   \n",
       "1 2023-01-15 08:45:00   CommuterX    Twitter   #Traffic #Morning         5   \n",
       "2 2023-01-15 15:45:00  FitnessFan  Instagram   #Fitness #Workout        20   \n",
       "3 2023-01-15 18:20:00  AdventureX   Facebook  #Travel #Adventure         8   \n",
       "4 2023-01-15 19:55:00    ChefCook  Instagram      #Cooking #Food        12   \n",
       "\n",
       "   Likes    Country  Year  Month  Day  Hour  \n",
       "0     30        USA  2023      1   15    12  \n",
       "1     10     Canada  2023      1   15     8  \n",
       "2     40        USA  2023      1   15    15  \n",
       "3     15         UK  2023      1   15    18  \n",
       "4     25  Australia  2023      1   15    19  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>User</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Hashtags</th>\n",
       "      <th>Retweets</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Country</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Hour</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enjoying a beautiful day at the park</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 12:30:00</td>\n",
       "      <td>User123</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Nature #Park</td>\n",
       "      <td>15</td>\n",
       "      <td>30</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Traffic was terrible this morning</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2023-01-15 08:45:00</td>\n",
       "      <td>CommuterX</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>#Traffic #Morning</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just finished an amazing workout</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 15:45:00</td>\n",
       "      <td>FitnessFan</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Fitness #Workout</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>USA</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excited about the upcoming weekend getaway</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2023-01-15 18:20:00</td>\n",
       "      <td>AdventureX</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>#Travel #Adventure</td>\n",
       "      <td>8</td>\n",
       "      <td>15</td>\n",
       "      <td>UK</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Trying out a new recipe for dinner tonight</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>2023-01-15 19:55:00</td>\n",
       "      <td>ChefCook</td>\n",
       "      <td>Instagram</td>\n",
       "      <td>#Cooking #Food</td>\n",
       "      <td>12</td>\n",
       "      <td>25</td>\n",
       "      <td>Australia</td>\n",
       "      <td>2023</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Text Sentiment           Timestamp  \\\n",
       "0        Enjoying a beautiful day at the park  Positive 2023-01-15 12:30:00   \n",
       "1           Traffic was terrible this morning  Negative 2023-01-15 08:45:00   \n",
       "2            Just finished an amazing workout  Positive 2023-01-15 15:45:00   \n",
       "3  Excited about the upcoming weekend getaway  Positive 2023-01-15 18:20:00   \n",
       "4  Trying out a new recipe for dinner tonight   Neutral 2023-01-15 19:55:00   \n",
       "\n",
       "         User   Platform            Hashtags  Retweets  Likes    Country  \\\n",
       "0     User123    Twitter       #Nature #Park        15     30        USA   \n",
       "1   CommuterX    Twitter   #Traffic #Morning         5     10     Canada   \n",
       "2  FitnessFan  Instagram   #Fitness #Workout        20     40        USA   \n",
       "3  AdventureX   Facebook  #Travel #Adventure         8     15         UK   \n",
       "4    ChefCook  Instagram      #Cooking #Food        12     25  Australia   \n",
       "\n",
       "   Year  Month  Day  Hour  \n",
       "0  2023      1   15    12  \n",
       "1  2023      1   15     8  \n",
       "2  2023      1   15    15  \n",
       "3  2023      1   15    18  \n",
       "4  2023      1   15    19  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T·ªïng quan c√°c b∆∞·ªõc x·ª≠ l√Ω d·ªØ li·ªáu:\n",
    "\n",
    "1. X√≥a C√°c d·ªØ li·ªáu l·ªói:\n",
    "\n",
    "1.1. X√≥a c·ªôt 'Unnamed: 0.1', 'Unnamed: 0'\n",
    "\n",
    "1.2 X√≥a c√°c k√Ω t·ª± ƒë·∫∑c bi·ªát ·ªü c·ªôt \"Text\"\n",
    "\n",
    "1.3 X√≥a kho·∫£ng tr·∫Øng ·ªü ƒë·∫ßu v√† cu·ªëi c√°c chu·ªói trong c√°c tr∆∞·ªùng d·ªØ li·ªáu c√≥ ki·ªÉu \"text\"\n",
    "\n",
    "2. Chu·∫©n h√≥a d·ªØ li·ªáu:\n",
    "\n",
    "2.1 ƒê·ªïi ƒë·ªãnh d·∫°ng c·ªôt 'Timestamp' th√†nh ki·ªÉu datetime\n",
    "\n",
    "2.2 ƒê·ªïi ƒë·ªãnh d·∫°ng c·ªôt 'Likes', 'Retweets' th√†nh ki·ªÉu int64\n",
    "\n",
    "2.3 Gi·ªõi h·∫°n chi·ªÅu d√†i chu·ªói t·ªëi ƒëa 255 k√Ω t·ª± c·ªßa c·ªôt Text\n",
    "\n",
    "3. T·∫°o dataframe m·ªõi (df1):\n",
    "\n",
    "3.1 Ph√¢n lo·∫°i c√°c c·∫£m x√∫c ·ªü c·ªôt 'Sentiment' th√†nh 3 nh√≥m c·∫£m x√∫c ch√≠nh:\n",
    "\n",
    " 3.1.1 T·∫°o c·ªôt 'Sumerize Sentiment' ch·ª©a values l√† d·ªØ li·ªáu ƒë√£ ph√¢n lo·∫°i ·ªü c·ªôt 'Sentiment'\n",
    "\n",
    "3.2 X√≥a c·ªôt 'Sentiment'\n",
    "\n",
    "3.3 ƒê·ªïi v·ªã tr√≠ c·ªôt 'Sumerize Sentiment'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. L∆∞u d·ªØ li·ªáu v·ªÅ file csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\HaoPham\\AppData\\Local\\Temp\\ipykernel_10468\\3121500483.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  df.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset.csv\", index=False)\n",
      "C:\\Users\\HaoPham\\AppData\\Local\\Temp\\ipykernel_10468\\3121500483.py:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  df1.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset01.csv\", index=False)\n",
      "C:\\Users\\HaoPham\\AppData\\Local\\Temp\\ipykernel_10468\\3121500483.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  df.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset.csv\", index=False)\n",
      "C:\\Users\\HaoPham\\AppData\\Local\\Temp\\ipykernel_10468\\3121500483.py:3: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  df1.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset01.csv\", index=False)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# L∆∞u df ƒë√£ x·ª≠ l√≠\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mE:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDATN\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSentiment_Analysis\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mcleaned_data\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43msentimentdataset.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df1\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mE:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDATN\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mSentiment_Analysis\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mcleaned_data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124msentimentdataset01.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# hashtags.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\hashtags.csv\", index=False, header=False)\u001b[39;00m\n",
      "File \u001b[1;32md:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3970\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3972\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3973\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3974\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3975\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3976\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3977\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3978\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3979\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3980\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3981\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3982\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3983\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3984\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32md:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32md:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[0;32m    748\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[1;32m--> 749\u001b[0m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    751\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[0;32m    752\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compression \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzstd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    753\u001b[0m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "File \u001b[1;32md:\\DATN\\Social Media Sentiments Analysis Dataset\\DeBug  data\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[0m, in \u001b[0;36mcheck_parent_directory\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m    614\u001b[0m parent \u001b[38;5;241m=\u001b[39m Path(path)\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent\u001b[38;5;241m.\u001b[39mis_dir():\n\u001b[1;32m--> 616\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mrf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot save file into a non-existent directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: Cannot save file into a non-existent directory: 'E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data'"
     ]
    }
   ],
   "source": [
    "# L∆∞u df ƒë√£ x·ª≠ l√≠\n",
    "df.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset.csv\", index=False)\n",
    "df1.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset01.csv\", index=False)\n",
    "# hashtags.to_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\hashtags.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ƒê√£ chuy·ªÉn ƒë·ªïi CSV th√†nh JSON th√†nh c√¥ng!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\KHANH\\AppData\\Local\\Temp\\ipykernel_50568\\2703791328.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  data_json = pd.read_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset01.csv\")\n",
      "C:\\Users\\KHANH\\AppData\\Local\\Temp\\ipykernel_50568\\2703791328.py:5: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  data_json.to_json(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset.json\", orient='records', lines=True)\n"
     ]
    }
   ],
   "source": [
    "# ƒê·ªçc d·ªØ li·ªáu t·ª´ file CSV\n",
    "data_json = pd.read_csv(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset01.csv\")\n",
    "\n",
    "# Chuy·ªÉn ƒë·ªïi DataFrame sang ƒë·ªãnh d·∫°ng JSON\n",
    "data_json.to_json(\"E:\\DATN\\Sentiment_Analysis\\data\\cleaned_data\\sentimentdataset.json\", orient='records', lines=True)\n",
    "\n",
    "print(\"ƒê√£ chuy·ªÉn ƒë·ªïi CSV th√†nh JSON th√†nh c√¥ng!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
